<!DOCTYPE html>
<html>
<body style="font-family: monospace">
Legend:<br>
    <text style="color:green">Green</text> — conversion successful<br>
    <text style="color:#b28c00">Yellow</text> — conversion imprecise<br>
    <text style="color:#ce0505">Red</text> — conversion failed<br>
    <text style="background-color:#ce0505;color:white">Red</text> — no converter found<br>
    <text style="font-weight:bold">Bold</text> — conversion applied directly<br>
    * — subgraph reused<br>
    <text style="background-color:black;color:white">Tensor</text> — this output is not dependent on any of subgraph's input tensors<br>
    <text style="text-decoration:underline">Tensor</text> — this input is a parameter / constant<br>
    <text style="color:#656565">Tensor</text> — this tensor is useless<br>
<br>
<text style="color:#ce0505">MyModule[__main__]</text>(<text style="">float32_0<1,3,256,256></text>) -> <text style="">float32_8<1,8,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:green;font-weight:bold">Conv2d[torch.nn.modules.conv]</text>(<text style="">float32_0<1,3,256,256></text>) -> <text style="">float32_3<1,16,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:green;font-weight:bold">&nbsp;└·</text> <text style="">conv2d[torch.nn.functional]</text>(<text style="">float32_0<1,3,256,256></text>, <text style="">float32_1<16,3,3,3></text>, <text style="">float32_2<16></text>, (2, 2), (1, 1), (1, 1), 1) -> <text style="">float32_3<1,16,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:#ce0505">Hardsigmoid[torch.nn.modules.activation]</text>(<text style="">float32_3<1,16,128,128></text>) -> <text style="">float32_4<1,16,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:#ce0505">&nbsp;└·</text> <text style="background-color:#ce0505;color:white">hardsigmoid[torch.nn.functional]</text>(<text style="">float32_3<1,16,128,128></text>, False) -> <text style="">float32_4<1,16,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:green;font-weight:bold">__getitem__[torch.Tensor]</text>(<text style="">float32_4<1,16,128,128></text>, (:, ::2)) -> <text style="">float32_5<1,8,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:green;font-weight:bold">__getitem__[torch.Tensor]</text>(<text style="">float32_4<1,16,128,128></text>, (:, 1::2)) -> <text style="">float32_6<1,8,128,128></text><br>
<text style="color:#ce0505">&nbsp;│&nbsp;</text> <text style="color:green;font-weight:bold">__mul__[torch.Tensor]</text>(<text style="">float32_5<1,8,128,128></text>, <text style="">float32_6<1,8,128,128></text>) -> <text style="">float32_7<1,8,128,128></text><br>
<text style="color:#ce0505">&nbsp;└·</text> <text style="color:green;font-weight:bold">__rsub__[torch.Tensor]</text>(<text style="">float32_7<1,8,128,128></text>, 1) -> <text style="">float32_8<1,8,128,128></text><br>
</body>
</html>