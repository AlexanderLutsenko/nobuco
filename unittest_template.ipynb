{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract functions from converter\n",
    "\n",
    "We need to extract\n",
    "\n",
    "```\n",
    "torch.log, torch.Tensor.log, torch.log_, torch.Tensor.log_\n",
    "```\n",
    "\n",
    "from the converter programmatically.\n",
    "\n",
    "They will be passed to AI, and it will make inputs of the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@converter(torch.log, torch.Tensor.log, torch.log_, torch.Tensor.log_, channel_ordering_strategy=ChannelOrderingStrategy.MINIMUM_TRANSPOSITIONS)\n",
    "def converter_log(input: Tensor, *, out: Optional[Tensor]=None):\n",
    "    def func(input, *, out: Optional[Tensor]=None):\n",
    "        return tf.math.log(input)\n",
    "    return func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unittest Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function target is assumed\n",
    "\n",
    "# The target to be converted\n",
    "func = torch.log\n",
    "\n",
    "# The function name representing the functions properly. Ex) log, do_something.\n",
    "# Option1 : Use the name of the first function. (preferred)\n",
    "# Option2 : Ask AI.\n",
    "# No matter what we choose, we must refine them.\n",
    "func_name = \"log\"\n",
    "\n",
    "# First Letter and letter after _ are capitalized. Ex) Log, DoSomething.\n",
    "Func_name = \"Log\"\n",
    "\n",
    "# Inputs as a list generated by AI.\n",
    "# It will be unpacked to be passed.\n",
    "# Would kwargs be better than args? It would be nice to try both.\n",
    "# Do we need 'r'? Maybe not, but make it sure that it is special-letter-free.\n",
    "inputs = r'[torch.ones(1, 10, 20), torch.ones(1, 10, 20)]'\n",
    "\n",
    "template = f\"\"\"\n",
    "def test_{func_name}_converter(self):\n",
    "    # Define the Sign model inside the test\n",
    "    class {Func_name}(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super({Func_name}, self).__init__()\n",
    "\n",
    "        def forward(self, input_tensor):\n",
    "            return {func}(input_tensor)\n",
    "\n",
    "    # Initialize the model and input tensor\n",
    "    torch_model = {Func_name}\n",
    "    torch_model.eval()\n",
    "    input_tensor = torch.randn(1, 10, 20)\n",
    "\n",
    "    # Convert the model and ensure the HTML trace is saved\n",
    "    keras_model = nobuco.pytorch_to_keras(\n",
    "        torch_model,\n",
    "        args=[*{inputs}], kwargs=None,\n",
    "        inputs_channel_order=nobuco.ChannelOrder.TENSORFLOW,\n",
    "        outputs_channel_order=nobuco.ChannelOrder.TENSORFLOW,\n",
    "        save_trace_html=True\n",
    "    )\n",
    "\n",
    "    # Read the contents of the trace.html file\n",
    "    with open('trace.html', 'r', encoding='utf-8') as file:\n",
    "        trace_html = file.read()\n",
    "\n",
    "    # Assertions for the content of trace_html\n",
    "    self.assertNotIn('Max diff', trace_html, \"The trace HTML should not contain 'Max diff'\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class target is assumed\n",
    "\n",
    "# The target to be converted\n",
    "constructor = 'torch.nn.Conv2'\n",
    "\n",
    "# The function name representing the functions properly. Ex) log, do_something.\n",
    "# Option1 : Use the name of the first function. (preferred)\n",
    "# Option2 : Ask AI.\n",
    "# No matter what we choose, we must refine them.\n",
    "class_name = \"log\"\n",
    "\n",
    "# Inputs as a list generated by AI.\n",
    "# It will be unpacked to be passed.\n",
    "# Would kwargs be better than args? It would be nice to try both.\n",
    "inputs = r'[torch.ones(1, 10, 20), torch.ones(1, 10, 20)]'\n",
    "\n",
    "# Another inputs are required to generate the target instance.\n",
    "# Try kwargs here.\n",
    "construction_args = r\"{'in_channels':10, 'out_channels':10, 'kernel_size'=1}\"\n",
    "\n",
    "template = f\"\"\"\n",
    "def test_{func_name}_converter(self):\n",
    "    # Initialize the model directly from its constructor\n",
    "    torch_model = {constructor}(**{construction_args})\n",
    "    torch_model.eval()\n",
    "\t# Initialize the model and input tensor\n",
    "    inputs = {inputs}\n",
    "\n",
    "    # Convert the model and ensure the HTML trace is saved\n",
    "    keras_model = nobuco.pytorch_to_keras(\n",
    "        torch_model,\n",
    "        args=[*inputs], kwargs=None,\n",
    "        inputs_channel_order=nobuco.ChannelOrder.TENSORFLOW,\n",
    "        outputs_channel_order=nobuco.ChannelOrder.TENSORFLOW,\n",
    "        save_trace_html=True\n",
    "    )\n",
    "\n",
    "    # Read the contents of the trace.html file\n",
    "    with open('trace.html', 'r', encoding='utf-8') as file:\n",
    "        trace_html = file.read()\n",
    "\n",
    "    # Assertions for the content of trace_html\n",
    "    self.assertNotIn('Max diff', trace_html, \"The trace HTML should not contain 'Max diff'\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# '__doc__`\n",
    "\n",
    "The documations can be extracted programmatically.\n",
    "The information can be very useful for the AI's tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import torch\n",
    "\n",
    "print(torch.nn.Conv2d.__doc__)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "0s\n",
    "import torch\n",
    "\n",
    "print(torch.nn.Conv2d.__doc__)\n",
    "Applies a 2D convolution over an input signal composed of several input\n",
    "    planes.\n",
    "\n",
    "    In the simplest case, the output value of the layer with input size\n",
    "    :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
    "    can be precisely described as:\n",
    "\n",
    "    .. math::\n",
    "        \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
    "        \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
    "\n",
    "\n",
    "    where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
    "    :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
    "    :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
    "    width in pixels.\n",
    "    \n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    * :attr:`stride` controls the stride for the cross-correlation, a single\n",
    "      number or a tuple.\n",
    "\n",
    "    * :attr:`padding` controls the amount of padding applied to the input. It\n",
    "      can be either a string {'valid', 'same'} or an int / a tuple of ints giving the\n",
    "      amount of implicit padding applied on both sides.\n",
    "\n",
    "    * :attr:`dilation` controls the spacing between the kernel points; also\n",
    "      known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
    "      has a nice visualization of what :attr:`dilation` does.\n",
    "\n",
    "    * :attr:`groups` controls the connections between inputs and outputs.\n",
    "      :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
    "      :attr:`groups`. For example,\n",
    "\n",
    "        * At groups=1, all inputs are convolved to all outputs.\n",
    "        * At groups=2, the operation becomes equivalent to having two conv\n",
    "          layers side by side, each seeing half the input channels\n",
    "          and producing half the output channels, and both subsequently\n",
    "          concatenated.\n",
    "        * At groups= :attr:`in_channels`, each input channel is convolved with\n",
    "          its own set of filters (of size\n",
    "          :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
    "\n",
    "    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
    "\n",
    "        - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
    "        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
    "          and the second `int` for the width dimension\n",
    "\n",
    "    Note:\n",
    "        When `groups == in_channels` and `out_channels == K * in_channels`,\n",
    "        where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
    "\n",
    "        In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
    "        a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
    "        :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
    "\n",
    "    Note:\n",
    "        In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
    "\n",
    "    Note:\n",
    "        ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
    "        the input so the output has the shape as the input. However, this mode\n",
    "        doesn't support any stride values other than 1.\n",
    "\n",
    "    Note:\n",
    "        This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int, tuple or str, optional): Padding added to all four sides of\n",
    "            the input. Default: 0\n",
    "        padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
    "            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        groups (int, optional): Number of blocked connections from input\n",
    "            channels to output channels. Default: 1\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the\n",
    "            output. Default: ``True``\n",
    "    \n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
    "        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
    "                        \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
    "                        \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
    "\n",
    "    Attributes:\n",
    "        weight (Tensor): the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
    "            :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
    "            The values of these weights are sampled from\n",
    "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
    "        bias (Tensor):   the learnable bias of the module of shape\n",
    "            (out_channels). If :attr:`bias` is ``True``,\n",
    "            then the values of these weights are\n",
    "            sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "            :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        >>> # With square kernels and equal stride\n",
    "        >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "        >>> # non-square kernels and unequal stride and with padding\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "        >>> # non-square kernels and unequal stride and with padding and dilation\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "        >>> input = torch.randn(20, 16, 50, 100)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    .. _cross-correlation:\n",
    "        https://en.wikipedia.org/wiki/Cross-correlation\n",
    "\n",
    "    .. _link:\n",
    "        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Args\n",
    "\n",
    "```\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input image\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (int or tuple): Size of the convolving kernel\n",
    "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
    "        padding (int, tuple or str, optional): Padding added to all four sides of\n",
    "            the input. Default: 0\n",
    "        padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
    "            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        groups (int, optional): Number of blocked connections from input\n",
    "            channels to output channels. Default: 1\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the\n",
    "            output. Default: ``True``\n",
    "```\n",
    "\n",
    "- Shape\n",
    "\n",
    "```\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C_{in}, H_{in}, W_{in})` or :math:`(C_{in}, H_{in}, W_{in})`\n",
    "        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` or :math:`(C_{out}, H_{out}, W_{out})`, where\n",
    "\n",
    "          .. math::\n",
    "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
    "                        \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
    "\n",
    "          .. math::\n",
    "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
    "                        \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
    "```\n",
    "\n",
    "- Examples\n",
    "\n",
    "```\n",
    "    Examples:\n",
    "\n",
    "        >>> # With square kernels and equal stride\n",
    "        >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "        >>> # non-square kernels and unequal stride and with padding\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "        >>> # non-square kernels and unequal stride and with padding and dilation\n",
    "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "        >>> input = torch.randn(20, 16, 50, 100)\n",
    "        >>> output = m(input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can it be fully deteministric? (no AI intervention)\n",
    "\n",
    "`__doc__` function provides the plenty of the information. Can we implement the automation fully pure programming?\n",
    "\n",
    "It would probably not possible because we are not sure if all the __doc__ has the same form.\n",
    "\n",
    "Do we still conduct some investigation on the feasibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we need RAG(Retrieval Augmented Generation)?\n",
    "\n",
    "- If we use chatgpt, it has the functionality in it. However, if the __doc__ is too long, we must reduce the length first.\n",
    "- If we use local LLM, it is a pure model generating outputs directly from the prompts\n",
    "- RAG might increase the performance, or might not. We can sort the necessary information, such as, args, shape and examples, and they are already very powerful. However, we don't know if some layers or functions have other important information.\n",
    "- Conclusion : Not necessary, so we implement without RAG. After the initial implementation is done, we can add RAG for further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase1\n",
    "\n",
    "# Prompt Template Blue Print\n",
    "# Not just the exact target, but the context\n",
    "# We'd better start with the smallest example\n",
    "\n",
    "doc = 'args, shape, example from __doc__'\n",
    "target = 'torch.nn.Conv2d'\n",
    "\n",
    "example = f'''\n",
    "target: torch.nn.Conv2d\n",
    "\n",
    "output:\n",
    "torch_model = torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3)\n",
    "'''\n",
    "\n",
    "prompt = f'''\n",
    "\n",
    "<<Documentation>>\n",
    "{doc}\n",
    "<</Documentation>>\n",
    "\n",
    "<<Example>>\n",
    "{example}\n",
    "<</Example>>\n",
    "\n",
    "Based on the context, generate the output.\n",
    "\n",
    "target: {target}\n",
    "\n",
    "output:\n",
    "torch_model = {target}\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "```\n",
    "output:\n",
    "torch model = {target}\n",
    "```\n",
    "\n",
    "Not sure with this part.\n",
    "Some examples use the stretage, but I have a negative experience with the scheme.\n",
    "\n",
    "Lets try different forms.\n",
    "\n",
    "1.\n",
    "output:\n",
    "torch_model = {target}\n",
    "\n",
    "2. \n",
    "output:\n",
    "\n",
    "3.\n",
    "output:\n",
    "torch_model = \n",
    "\n",
    "It might not matter.  Whatever AI generates, we can extract the text after the target programmatically.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2\n",
    "\n",
    "# Check if an instance is initiated by the generated text\n",
    "# If the test fails, return to Phase1\n",
    "# If passes, do the next\n",
    "\n",
    "# Phase1\n",
    "\n",
    "# Prompt Template Blue Print\n",
    "# Not just the exact target, but the context\n",
    "# We'd better start with the smallest example\n",
    "\n",
    "doc = 'args, shape, example from __doc__'\n",
    "target = 'torch.nn.Conv2d'\n",
    "\n",
    "example = f'''\n",
    "target: \n",
    "torch_model = torch.nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3)\n",
    "\n",
    "output:\n",
    "output = torch_model.forward(inputs)\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = f'''\n",
    "\n",
    "<<Documentation>>\n",
    "{doc}\n",
    "<</Documentation>>\n",
    "\n",
    "<<Example>>\n",
    "{example}\n",
    "<</Example>>\n",
    "\n",
    "Based on the context, generate the output.\n",
    "\n",
    "target: {target}\n",
    "\n",
    "output:\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
